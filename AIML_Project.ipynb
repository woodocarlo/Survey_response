{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = r'path.csv'\n",
        "excel_file = pd.ExcelFile(file_path)\n",
        "\n",
        "# Check if 'Responses' and 'Time Taken' sheets exist\n",
        "if 'Responses' in excel_file.sheet_names and 'Time Taken' in excel_file.sheet_names:\n",
        "    # Load the sheets\n",
        "    df_responses = pd.read_excel(excel_file, 'Responses', header=0)\n",
        "    df_timings = pd.read_excel(excel_file, 'Time Taken', header=0)\n",
        "\n",
        "    # Combine the data into JSON format\n",
        "    combined_data = []\n",
        "    for i, row in df_responses.iterrows():\n",
        "        combined_row = {}\n",
        "        for col in df_responses.columns:\n",
        "            # Match the corresponding column in the 'Time Taken' sheet\n",
        "            timing_col = f\"Q{df_responses.columns.get_loc(col) + 1} (seconds)\"\n",
        "            combined_row[col] = json.dumps({\n",
        "                \"responses\": row[col],\n",
        "                \"time taken\": df_timings.at[i, timing_col] if timing_col in df_timings.columns else None\n",
        "            })\n",
        "        combined_data.append(combined_row)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    combined_df = pd.DataFrame(combined_data)\n",
        "\n",
        "    # Save the combined DataFrame to a new Excel file\n",
        "    combined_df.to_excel('/contents/Response-time_format.xlsx', index=False)\n",
        "    print(\"Combined data has been saved to 'Combined_Survey_Output.xlsx'\")\n",
        "else:\n",
        "    print(\"Worksheet 'Responses' or 'Time Taken' not found in the file.\")"
      ],
      "metadata": {
        "id": "z2vyPLGr53Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preproccessing the data**"
      ],
      "metadata": {
        "id": "QKB1ISNyTZV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# Corrected Data\n",
        "data = {\n",
        "    \"Category\": [\"Rush\"],\n",
        "    \"SUB(Q1)\": ['{\"response_length\": 39, \"time taken\": 6.47}'],\n",
        "    \"MCQ(Q2)\": ['{\"responses\": \"b\", \"time taken\": 19.23}'],\n",
        "    \"MMCQ(Q1)\": ['{\"responses\": \"b, c, a, d, e\", \"time taken\": 24.93}'],\n",
        "    \"SUB(Q2)\": ['{\"response_length\": 87, \"time taken\": 33.51}'],\n",
        "    \"MCQ(Q3)\": ['{\"responses\": \"c\", \"time taken\": 75.48}'],\n",
        "    \"MMCQ(Q2)\": ['{\"responses\": \"a\", \"time taken\": 76.6}'],\n",
        "    \"SUB(Q3)\": ['{\"response_length\": 39, \"time taken\": 84.6}'],\n",
        "    \"MCQ(Q4)\": ['{\"responses\": \"c\", \"time taken\": 110.52}'],\n",
        "    \"SUB(Q4)\": ['{\"response_length\": 33, \"time taken\": 114.99}'],\n",
        "    \"MCQ(Q5)\": ['{\"responses\": \"b\", \"time taken\": 138.23}'],\n",
        "    \"MMCQ(Q3)\": ['{\"responses\": \"c\", \"time taken\": 144.2}'],\n",
        "    \"MCQ(Q6)\": ['{\"responses\": \"c\", \"time taken\": 146.53}'],\n",
        "    \"SUB(Q5)\": ['{\"response_length\": 47, \"time taken\": 149.92}'],\n",
        "    \"MMCQ(Q4)\": ['{\"responses\": \"b, a, c, e, d\", \"time taken\": 162.32}'],\n",
        "    \"MCQ(Q7)\": ['{\"responses\": \"a\", \"time taken\": 168.13}'],\n",
        "    \"SUB(Q6)\": ['{\"response_length\": 2, \"time taken\": 172.03}'],\n",
        "    \"MMCQ(Q5)\": ['{\"responses\": \"b\", \"time taken\": 176.82}'],\n",
        "    \"MCQ(Q8)\": ['{\"responses\": \"c\", \"time taken\": 178.1}'],\n",
        "    \"SUB(Q7)\": ['{\"response_length\": 88, \"time taken\": 184.83}'],\n",
        "    \"Non-attempt\": [0],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Function to calculate selection pattern, unique options, most common option, and diversity score\n",
        "def calc_mcq_features(columns):\n",
        "    selection_patterns = []\n",
        "    unique_options_list = []\n",
        "    most_common_options = []\n",
        "    diversity_scores = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        all_responses = []\n",
        "        for col in columns:\n",
        "            try:\n",
        "                response_data = json.loads(row[col])\n",
        "                responses = response_data[\"responses\"].split(\", \")\n",
        "                all_responses.extend(responses)\n",
        "            except (KeyError, json.JSONDecodeError):\n",
        "                continue\n",
        "        # Calculate features\n",
        "        selection_patterns.append(\" -> \".join(all_responses))\n",
        "        unique_options = set(all_responses)\n",
        "        unique_options_list.append(len(unique_options))\n",
        "        most_common_option = Counter(all_responses).most_common(1)\n",
        "        most_common_options.append(most_common_option[0][0] if most_common_option else None)\n",
        "        diversity_scores.append(len(unique_options) / len(all_responses) if all_responses else 0)\n",
        "\n",
        "    return selection_patterns, unique_options_list, most_common_options, diversity_scores\n",
        "\n",
        "# MCQ/MMCQ columns\n",
        "mcq_cols = [col for col in df.columns if col.startswith(\"MCQ\") or col.startswith(\"MMCQ\")]\n",
        "\n",
        "# Add MCQ features\n",
        "df[\"Selection_Pattern\"], df[\"Unique_Options\"], df[\"Most_Common_Option\"], df[\"Diversity_Score\"] = calc_mcq_features(mcq_cols)\n",
        "\n",
        "# Function to calculate total time for MCQ/MMCQ questions\n",
        "def calc_total_time(columns):\n",
        "    total_times = []\n",
        "    for _, row in df.iterrows():\n",
        "        total_time = 0\n",
        "        for col in columns:\n",
        "            try:\n",
        "                response_data = json.loads(row[col])\n",
        "                time_taken = response_data[\"time taken\"]\n",
        "                total_time += time_taken\n",
        "            except (KeyError, json.JSONDecodeError):\n",
        "                continue\n",
        "        total_times.append(total_time)\n",
        "    return total_times\n",
        "\n",
        "# Add total_Time_Per_Response column\n",
        "df[\"Total_Time_Per_Response\"] = calc_total_time(mcq_cols)\n",
        "\n",
        "# Function to calculate subjective metrics (length and time)\n",
        "def calc_subjective_metrics(columns):\n",
        "    total_lengths = []\n",
        "    total_times = []\n",
        "    for _, row in df.iterrows():\n",
        "        total_length = 0\n",
        "        total_time = 0\n",
        "        for col in columns:\n",
        "            try:\n",
        "                response_data = json.loads(row[col])\n",
        "                total_length += response_data.get(\"response_length\", 0)\n",
        "                total_time += response_data.get(\"time taken\", 0)\n",
        "            except (KeyError, json.JSONDecodeError):\n",
        "                continue\n",
        "        total_lengths.append(total_length)\n",
        "        total_times.append(total_time)\n",
        "    return total_lengths, total_times\n",
        "\n",
        "# Subjective question columns\n",
        "sub_cols = [col for col in df.columns if col.startswith(\"SUB\")]\n",
        "\n",
        "# Add Total_Sub_Length and Total_Sub_Time columns\n",
        "df['Total_Sub_Length'], df['Total_Sub_Time'] = calc_subjective_metrics(sub_cols)\n",
        "\n",
        "# Calculate Avg_Typing_Speed (length per second)\n",
        "df['Avg_Typing_Speed'] = df['Total_Sub_Length'] / df['Total_Sub_Time']\n",
        "\n",
        "# Final dataframe\n",
        "final_columns = ['Category', 'Selection_Pattern', 'Unique_Options', 'Most_Common_Option',\n",
        "                 'Diversity_Score', 'Total_Time_Per_Response', 'Total_Sub_Length',\n",
        "                 'Total_Sub_Time', 'Avg_Typing_Speed', 'Non-attempt']\n",
        "final_df = df[final_columns]\n",
        "\n",
        "# Display the final processed DataFrame\n",
        "print(final_df)\n",
        "\n",
        "# Save to Excel\n",
        "output_file = \"processed_data2.xlsx\"\n",
        "final_df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Data has been successfully saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nmSJJMgufO8",
        "outputId": "eb9ff682-0880-42fa-ee6d-052164d73365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category                                  Selection_Pattern  Unique_Options  \\\n",
            "0  Genuine  b -> b -> c -> a -> d -> e -> c -> a -> c -> b...               5   \n",
            "\n",
            "  Most_Common_Option  Diversity_Score  Total_Time_Per_Response  \\\n",
            "0                  c             0.25                  1421.09   \n",
            "\n",
            "   Total_Sub_Length  Total_Sub_Time  Avg_Typing_Speed  Non-attempt  \n",
            "0               335          746.35          0.448851            0  \n",
            "Data has been successfully saved to processed_data2.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the data**"
      ],
      "metadata": {
        "id": "oSKJwPJnTeeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the specified path\n",
        "file_path = \"/content/adjusted_dataset.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Preview the dataset\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChCsxv1gyxYB",
        "outputId": "70a71f15-7235-470e-e249-bfbc909623cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category                                  Selection_Pattern  Unique_Options  \\\n",
            "0  Genuine  b -> b -> c -> a -> d -> e -> c -> a -> c -> b...               5   \n",
            "1     Rush  a -> a -> c -> d -> a -> e -> d -> c -> a -> b...               5   \n",
            "2  Genuine  a -> d -> c -> a -> a -> b -> e -> d -> c -> b...               5   \n",
            "3  Genuine  a -> d -> c -> a -> a -> b -> e -> d -> c -> b...               5   \n",
            "4  Genuine  c -> a -> d -> e -> a -> d -> d -> e -> b -> d...               5   \n",
            "\n",
            "  Most_Common_Option  Diversity_Score  Total_Time_Per_Response  \\\n",
            "0                  c           0.2500                     1421   \n",
            "1                  a           0.3125                     1035   \n",
            "2                  a           0.2500                     2045   \n",
            "3                  a           0.2500                     2045   \n",
            "4                  d           0.3125                     1113   \n",
            "\n",
            "   Total_Sub_Length  Total_Sub_Time  Avg_Typing_Speed  Non-attempt  \n",
            "0            746.35        0.448851          0.448851            0  \n",
            "1            465.08        0.204266          0.204266            1  \n",
            "2           3464.77        0.051086          0.051086            0  \n",
            "3           3464.77        0.051086          0.051086            0  \n",
            "4            603.01        0.459362          0.459362            0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop('Category', axis=1)  # Drop the target column\n",
        "y = data['Category']  # Target column\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Convert non-numeric columns to numeric using one-hot encoding\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Train-test split (keeping all data for training)\n",
        "X_train, _, y_train, _ = train_test_split(X_encoded, y_encoded, test_size=0.001, random_state=42)\n",
        "\n",
        "# Now X_train and y_train contain all the data for training\n"
      ],
      "metadata": {
        "id": "TG7k_h73y8Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trainng and testing bgt model**"
      ],
      "metadata": {
        "id": "-bwh_pUHTLlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Load your training data\n",
        "data = pd.read_csv('/content/adjusted_dataset.csv')  # Replace with the path to your training data\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop('Category', axis=1)  # Drop the target column\n",
        "y = data['Category']  # Target column\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Convert non-numeric columns to numeric using one-hot encoding\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Train-test split (keeping all data for training)\n",
        "X_train, _, y_train, _ = train_test_split(X_encoded, y_encoded, test_size=0.01, random_state=42)\n",
        "\n",
        "# Initialize the GBT model\n",
        "gbt_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\n",
        "\n",
        "# Train the model using preprocessed training data\n",
        "gbt_model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained BGT model to a file\n",
        "joblib.dump(gbt_model, 'bgt_model.pkl')  # Saves the model as 'bgt_model.pkl'\n",
        "print(\"BGT model has been saved as 'bgt_model.pkl'.\")\n",
        "\n",
        "# Ask for the location URL of the Excel file containing the data to be tested\n",
        "excel_url = input(\"Enter the location URL of the Excel file containing the data to be tested: \")\n",
        "\n",
        "# Load the test data from the Excel file\n",
        "test_data = pd.read_excel(excel_url, sheet_name='Sheet1')\n",
        "\n",
        "# Prepare the test data for prediction\n",
        "test_features = test_data[['Selection_Pattern', 'Unique_Options', 'Most_Common_Option', 'Diversity_Score', 'Total_Time_Per_Response', 'Total_Sub_Length', 'Total_Sub_Time', 'Avg_Typing_Speed', 'Non-attempt']]\n",
        "test_features_encoded = pd.get_dummies(test_features, drop_first=True)\n",
        "\n",
        "# Ensure the test data has the same columns as the training data\n",
        "missing_cols = set(X_train.columns) - set(test_features_encoded.columns)\n",
        "for col in missing_cols:\n",
        "    test_features_encoded[col] = 0\n",
        "test_features_encoded = test_features_encoded[X_train.columns]\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred_test = gbt_model.predict(test_features_encoded)\n",
        "y_pred_proba = gbt_model.predict_proba(test_features_encoded)\n",
        "\n",
        "# Print the predictions with probabilities\n",
        "print(\"Predictions for the test data:\")\n",
        "for i in range(len(y_pred_test)):\n",
        "    if y_pred_test[i] == 0:\n",
        "        print(f\"Row {i+1}: The survey was a rush attempt with probability {y_pred_proba[i][0] * 100:.2f}%\")\n",
        "    else:\n",
        "        print(f\"Row {i+1}: The survey was a genuine attempt with probability {y_pred_proba[i][1] * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em-lsAEtQRax",
        "outputId": "0f57e227-3249-4a86-ce77-8dd2d97f33fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:36:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BGT model has been saved as 'bgt_model.pkl'.\n",
            "Enter the location URL of the Excel file containing the data to be tested: /content/processed_data2.xlsx\n",
            "Predictions for the test data:\n",
            "Row 1: The survey was a genuine attempt with probability 94.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOGICAL ANALYSIS**"
      ],
      "metadata": {
        "id": "1bxTq7USTGLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Initialize the model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "def check_logical_connection(question1, question2, answer1, answer2, question_threshold=0.75, answer_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Determines logical connection between questions and their answers based on similarity thresholds.\n",
        "    \"\"\"\n",
        "    # Encode questions and answers\n",
        "    question1_embedding = model.encode(question1)\n",
        "    question2_embedding = model.encode(question2)\n",
        "    answer1_embedding = model.encode(answer1)\n",
        "    answer2_embedding = model.encode(answer2)\n",
        "\n",
        "    # Calculate cosine similarity for questions\n",
        "    question_similarity = util.cos_sim(question1_embedding, question2_embedding).item()\n",
        "\n",
        "    if question_similarity >= question_threshold:\n",
        "        # If questions are similar, check the similarity of the answers\n",
        "        answer_similarity = util.cos_sim(answer1_embedding, answer2_embedding).item()\n",
        "\n",
        "        if answer_similarity >= answer_threshold:\n",
        "            return True, question_similarity, answer_similarity  # Both questions and answers are logically connected\n",
        "\n",
        "    return False, question_similarity, None\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to process the survey script, identify related questions,\n",
        "    and analyze logical connections in the responses.\n",
        "    \"\"\"\n",
        "    # Prompt user to enter survey script in JSON format\n",
        "    survey_script = input(\"Enter the survey script in JSON format: \")\n",
        "    survey_data = json.loads(survey_script)\n",
        "\n",
        "    # Extract questions and options\n",
        "    questions = {q['id']: q['questionText'] for q in survey_data['questions']}\n",
        "    options = {q['id']: q['options'] for q in survey_data['questions']}\n",
        "\n",
        "    # Print related questions based on question similarity\n",
        "    print(\"Related Questions with Similarity Scores:\")\n",
        "    for q1_id, q1_text in questions.items():\n",
        "        for q2_id, q2_text in questions.items():\n",
        "            if q1_id != q2_id:\n",
        "                _, question_similarity, _ = check_logical_connection(q1_text, q2_text, \"\", \"\")\n",
        "                if question_similarity >= 0.75:  # Adjust threshold as needed\n",
        "                    print(f\"Questions '{q1_text}' and '{q2_text}' have a similarity score of {question_similarity:.2f}\")\n",
        "\n",
        "    # Load survey responses from an Excel file\n",
        "    excel_url = input(\"Enter the location URL of the Excel file containing the responses: \")\n",
        "    df = pd.read_excel(excel_url, sheet_name='Responses')\n",
        "\n",
        "    # Compare logical connections for each row in the survey data\n",
        "    for i, row in df.iterrows():\n",
        "        for q1_id, q1_text in questions.items():\n",
        "            for q2_id, q2_text in questions.items():\n",
        "                if q1_id != q2_id:\n",
        "                    answer1 = row[q1_text] if pd.notna(row[q1_text]) else \"\"\n",
        "                    answer2 = row[q2_text] if pd.notna(row[q2_text]) else \"\"\n",
        "                    is_connected, question_similarity, answer_similarity = check_logical_connection(q1_text, q2_text, answer1, answer2)\n",
        "                    if is_connected:\n",
        "                        print(f\"Row {i+1}: Questions '{q1_text}' and '{q2_text}' are logically connected with question similarity {question_similarity:.2f} and answer similarity {answer_similarity:.2f}.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxRe5vCH0kQ4",
        "outputId": "a894e507-f921-4972-f933-edffa2e37372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the survey script in JSON format: {   \"title\": \"Survey - 2 (AI)\",   \"questions\": [     {       \"id\": \"question-1\",       \"type\": \"mcq\",       \"mandatory\": true,       \"questionText\": \"Is this a genuine attempt or a rush attempt?\",       \"options\": [         \"Genuine Attempt\",         \"Rush Attempt\"       ]     },     {       \"id\": \"question-2\",       \"type\": \"subjective\",       \"mandatory\": true,       \"questionText\": \"What do you think is the most exciting application of AI in today's world?\",       \"options\": []     },     {       \"id\": \"question-3\",       \"type\": \"mcq\",       \"mandatory\": true,       \"questionText\": \"Which area of AI do you think will grow the most in the next 5 years?\",       \"options\": [         \"Healthcare\",         \"Education\",         \"Finance\",         \"Entertainment\",         \"Transportation\"       ]     },     {       \"id\": \"question-4\",       \"type\": \"multi-select\",       \"mandatory\": false,       \"questionText\": \"Which challenges of AI development concern you the most?\",       \"options\": [         \"Data Privacy\",         \"Ethical Issues\",         \"Job Displacement\",         \"Bias in Algorithms\",         \"Environmental Impact\"       ]     },     {       \"id\": \"question-5\",       \"type\": \"subjective\",       \"mandatory\": false,       \"questionText\": \"Do you think AI can completely replace human decision-making? Why or why not?\",       \"options\": []     },     {       \"id\": \"question-6\",       \"type\": \"mcq\",       \"mandatory\": false,       \"questionText\": \"How comfortable are you with AI being used in day-to-day decisions like hiring or loans?\",       \"options\": [         \"Very Comfortable\",         \"Somewhat Comfortable\",         \"Neutral\",         \"Somewhat Uncomfortable\",         \"Very Uncomfortable\"       ]     },     {       \"id\": \"question-7\",       \"type\": \"multi-select\",       \"mandatory\": false,       \"questionText\": \"What do you believe are the biggest advantages of using AI?\",       \"options\": [         \"Increased Efficiency\",         \"Cost Reduction\",         \"Enhanced Accuracy\",         \"Better Insights\",         \"24/7 Availability\"       ]     },     {       \"id\": \"question-8\",       \"type\": \"subjective\",       \"mandatory\": true,       \"questionText\": \"What ethical guidelines would you propose for the development of AI systems?\",       \"options\": []     },     {       \"id\": \"question-9\",       \"type\": \"mcq\",       \"mandatory\": true,       \"questionText\": \"How optimistic are you about AI’s role in shaping the future?\",       \"options\": [         \"Very Optimistic\",         \"Somewhat Optimistic\",         \"Neutral\",         \"Somewhat Pessimistic\",         \"Very Pessimistic\"       ]     },     {       \"id\": \"question-10\",       \"type\": \"subjective\",       \"mandatory\": false,       \"questionText\": \"What improvements or features would you like to see in AI-based technologies you use?\",       \"options\": []     },     {       \"id\": \"question-11\",       \"type\": \"mcq\",       \"mandatory\": false,       \"questionText\": \"What is your main source of information about AI advancements?\",       \"options\": [         \"News Websites\",         \"Social Media\",         \"Research Papers\",         \"Workplace Discussions\",         \"Others\"       ]     },     {       \"id\": \"question-12\",       \"type\": \"multi-select\",       \"mandatory\": true,       \"questionText\": \"Which industries do you think are most at risk of disruption due to AI?\",       \"options\": [         \"Manufacturing\",         \"Customer Service\",         \"Healthcare\",         \"Transportation\",         \"Retail\"       ]     },     {       \"id\": \"question-13\",       \"type\": \"mcq\",       \"mandatory\": false,       \"questionText\": \"How would you rate your knowledge of AI?\",       \"options\": [         \"Expert\",         \"Intermediate\",         \"Beginner\",         \"Minimal Knowledge\",         \"No Knowledge\"       ]     },     {       \"id\": \"question-14\",       \"type\": \"subjective\",       \"mandatory\": false,       \"questionText\": \"If you could create an AI tool, what problem would it solve, and how?\",       \"options\": []     },     {       \"id\": \"question-15\",       \"type\": \"multi-select\",       \"mandatory\": false,       \"questionText\": \"Which AI-powered tools or applications do you use regularly?\",       \"options\": [         \"Virtual Assistants (Alexa, Siri)\",         \"Recommendation Systems (Netflix, Spotify)\",         \"Image/Video Processing Tools\",         \"Chatbots\",         \"Others\"       ]     },     {       \"id\": \"question-16\",       \"type\": \"mcq\",       \"mandatory\": true,       \"questionText\": \"Do you believe AI should be regulated?\",       \"options\": [         \"Yes, Strictly Regulated\",         \"Yes, with Moderate Regulations\",         \"No Regulation Needed\",         \"Not Sure\"       ]     },     {       \"id\": \"question-17\",       \"type\": \"subjective\",       \"mandatory\": true,       \"questionText\": \"What is your opinion on AI being used in creative fields like art or music?\",       \"options\": []     },     {       \"id\": \"question-18\",       \"type\": \"multi-select\",       \"mandatory\": true,       \"questionText\": \"What are your biggest fears about AI development?\",       \"options\": [         \"Loss of Privacy\",         \"AI Misuse by Governments\",         \"Uncontrollable AI\",         \"Loss of Human Jobs\",         \"None of the Above\"       ]     },     {       \"id\": \"question-19\",       \"type\": \"mcq\",       \"mandatory\": false,       \"questionText\": \"How often do you engage with AI-based tools or technologies?\",       \"options\": [         \"Daily\",         \"Weekly\",         \"Occasionally\",         \"Rarely\",         \"Never\"       ]     },     {       \"id\": \"question-20\",       \"type\": \"subjective\",       \"mandatory\": true,       \"questionText\": \"Any final thoughts or suggestions you would like to share about the future of AI?\",       \"options\": []     }   ],   \"excelUrl\": \"\" }\n",
            "Related Questions with Similarity Scores:\n",
            "Questions 'Which challenges of AI development concern you the most?' and 'What are your biggest fears about AI development?' have a similarity score of 0.82\n",
            "Questions 'What do you believe are the biggest advantages of using AI?' and 'What improvements or features would you like to see in AI-based technologies you use?' have a similarity score of 0.75\n",
            "Questions 'What do you believe are the biggest advantages of using AI?' and 'What is your main source of information about AI advancements?' have a similarity score of 0.76\n",
            "Questions 'How optimistic are you about AI’s role in shaping the future?' and 'Any final thoughts or suggestions you would like to share about the future of AI?' have a similarity score of 0.78\n",
            "Questions 'What improvements or features would you like to see in AI-based technologies you use?' and 'What do you believe are the biggest advantages of using AI?' have a similarity score of 0.75\n",
            "Questions 'What is your main source of information about AI advancements?' and 'What do you believe are the biggest advantages of using AI?' have a similarity score of 0.76\n",
            "Questions 'Which AI-powered tools or applications do you use regularly?' and 'How often do you engage with AI-based tools or technologies?' have a similarity score of 0.80\n",
            "Questions 'What are your biggest fears about AI development?' and 'Which challenges of AI development concern you the most?' have a similarity score of 0.82\n",
            "Questions 'How often do you engage with AI-based tools or technologies?' and 'Which AI-powered tools or applications do you use regularly?' have a similarity score of 0.80\n",
            "Questions 'Any final thoughts or suggestions you would like to share about the future of AI?' and 'How optimistic are you about AI’s role in shaping the future?' have a similarity score of 0.78\n",
            "Enter the location URL of the Excel file containing the responses: /content/survey-29.xlsx\n",
            "Row 1: Questions 'Which AI-powered tools or applications do you use regularly?' and 'How often do you engage with AI-based tools or technologies?' are logically connected with question similarity 0.80 and answer similarity 0.55.\n",
            "Row 1: Questions 'How often do you engage with AI-based tools or technologies?' and 'Which AI-powered tools or applications do you use regularly?' are logically connected with question similarity 0.80 and answer similarity 0.55.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BGT+LOGICAL FINAL MODEL**"
      ],
      "metadata": {
        "id": "yUecshzPS6-v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZVbSDHv5Zca",
        "outputId": "747e722c-447d-48a7-b686-a0c575d6ac20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the survey script in JSON format: {   \"title\": \"Survey - 2 (AI)\",   \"questions\": [     {       \"id\": \"question-1\",       \"type\": \"mcq\",       \"mandatory\": true,       \"questionText\": \"Is this a genuine attempt or a rush attempt?\",       \"options\": [         \"Genuine Attempt\",         \"Rush Attempt\"       ]     },     {       \"id\": \"question-2\",       \"type\": \"subjective\",       \"mandatory\": true,       \"questionText\": \"What do you think is the most exciting application of AI in today's world?\",       \"options\": []     },     {       \"id\": \"question-3\",       \"type\": \"mcq\",       \"mandatory\": true,       \"questionText\": \"Which area of AI do you think will grow the most in the next 5 years?\",       \"options\": [         \"Healthcare\",         \"Education\",         \"Finance\",         \"Entertainment\",         \"Transportation\"       ]     },     {       \"id\": \"question-4\",       \"type\": \"multi-select\",       \"mandatory\": false,       \"questionText\": \"Which challenges of AI development concern you the most?\",       \"options\": [         \"Data Privacy\",         \"Ethical Issues\",         \"Job Displacement\",         \"Bias in Algorithms\",         \"Environmental Impact\"       ]     },     {       \"id\": \"question-5\",       \"type\": \"subjective\",       \"mandatory\": false,       \"questionText\": \"Do you think AI can completely replace human decision-making? Why or why not?\",       \"options\": []     },     {       \"id\": \"question-6\",       \"type\": \"mcq\",       \"mandatory\": false,       \"questionText\": \"How comfortable are you with AI being used in day-to-day decisions like hiring or loans?\",       \"options\": [         \"Very Comfortable\",         \"Somewhat Comfortable\",         \"Neutral\",         \"Somewhat Uncomfortable\",         \"Very Uncomfortable\"       ]     },     {       \"id\": \"question-7\",       \"type\": \"multi-select\",       \"mandatory\": false,       \"questionText\": \"What do you believe are the biggest advantages of using AI?\",       \"options\": [         \"Increased Efficiency\",         \"Cost Reduction\",         \"Enhanced Accuracy\",         \"Better Insights\",         \"24/7 Availability\"       ]     },     {       \"id\": \"question-8\",       \"type\": \"subjective\",       \"mandatory\": true,       \"questionText\": \"What ethical guidelines would you propose for the development of AI systems?\",       \"options\": []     },     {       \"id\": \"question-9\",       \"type\": \"mcq\",       \"mandatory\": true,       \"questionText\": \"How optimistic are you about AI’s role in shaping the future?\",       \"options\": [         \"Very Optimistic\",         \"Somewhat Optimistic\",         \"Neutral\",         \"Somewhat Pessimistic\",         \"Very Pessimistic\"       ]     },     {       \"id\": \"question-10\",       \"type\": \"subjective\",       \"mandatory\": false,       \"questionText\": \"What improvements or features would you like to see in AI-based technologies you use?\",       \"options\": []     },     {       \"id\": \"question-11\",       \"type\": \"mcq\",       \"mandatory\": false,       \"questionText\": \"What is your main source of information about AI advancements?\",       \"options\": [         \"News Websites\",         \"Social Media\",         \"Research Papers\",         \"Workplace Discussions\",         \"Others\"       ]     },     {       \"id\": \"question-12\",       \"type\": \"multi-select\",       \"mandatory\": true,       \"questionText\": \"Which industries do you think are most at risk of disruption due to AI?\",       \"options\": [         \"Manufacturing\",         \"Customer Service\",         \"Healthcare\",         \"Transportation\",         \"Retail\"       ]     },     {       \"id\": \"question-13\",       \"type\": \"mcq\",       \"mandatory\": false,       \"questionText\": \"How would you rate your knowledge of AI?\",       \"options\": [         \"Expert\",         \"Intermediate\",         \"Beginner\",         \"Minimal Knowledge\",         \"No Knowledge\"       ]     },     {       \"id\": \"question-14\",       \"type\": \"subjective\",       \"mandatory\": false,       \"questionText\": \"If you could create an AI tool, what problem would it solve, and how?\",       \"options\": []     },     {       \"id\": \"question-15\",       \"type\": \"multi-select\",       \"mandatory\": false,       \"questionText\": \"Which AI-powered tools or applications do you use regularly?\",       \"options\": [         \"Virtual Assistants (Alexa, Siri)\",         \"Recommendation Systems (Netflix, Spotify)\",         \"Image/Video Processing Tools\",         \"Chatbots\",         \"Others\"       ]     },     {       \"id\": \"question-16\",       \"type\": \"mcq\",       \"mandatory\": true,       \"questionText\": \"Do you believe AI should be regulated?\",       \"options\": [         \"Yes, Strictly Regulated\",         \"Yes, with Moderate Regulations\",         \"No Regulation Needed\",         \"Not Sure\"       ]     },     {       \"id\": \"question-17\",       \"type\": \"subjective\",       \"mandatory\": true,       \"questionText\": \"What is your opinion on AI being used in creative fields like art or music?\",       \"options\": []     },     {       \"id\": \"question-18\",       \"type\": \"multi-select\",       \"mandatory\": true,       \"questionText\": \"What are your biggest fears about AI development?\",       \"options\": [         \"Loss of Privacy\",         \"AI Misuse by Governments\",         \"Uncontrollable AI\",         \"Loss of Human Jobs\",         \"None of the Above\"       ]     },     {       \"id\": \"question-19\",       \"type\": \"mcq\",       \"mandatory\": false,       \"questionText\": \"How often do you engage with AI-based tools or technologies?\",       \"options\": [         \"Daily\",         \"Weekly\",         \"Occasionally\",         \"Rarely\",         \"Never\"       ]     },     {       \"id\": \"question-20\",       \"type\": \"subjective\",       \"mandatory\": true,       \"questionText\": \"Any final thoughts or suggestions you would like to share about the future of AI?\",       \"options\": []     }   ],   \"excelUrl\": \"\" }\n",
            "Related Questions with Similarity Scores:\n",
            "Questions 'Which challenges of AI development concern you the most?' and 'What are your biggest fears about AI development?' have a similarity score of 0.82\n",
            "Questions 'What do you believe are the biggest advantages of using AI?' and 'What improvements or features would you like to see in AI-based technologies you use?' have a similarity score of 0.75\n",
            "Questions 'What do you believe are the biggest advantages of using AI?' and 'What is your main source of information about AI advancements?' have a similarity score of 0.76\n",
            "Questions 'How optimistic are you about AI’s role in shaping the future?' and 'Any final thoughts or suggestions you would like to share about the future of AI?' have a similarity score of 0.78\n",
            "Questions 'What improvements or features would you like to see in AI-based technologies you use?' and 'What do you believe are the biggest advantages of using AI?' have a similarity score of 0.75\n",
            "Questions 'What is your main source of information about AI advancements?' and 'What do you believe are the biggest advantages of using AI?' have a similarity score of 0.76\n",
            "Questions 'Which AI-powered tools or applications do you use regularly?' and 'How often do you engage with AI-based tools or technologies?' have a similarity score of 0.80\n",
            "Questions 'What are your biggest fears about AI development?' and 'Which challenges of AI development concern you the most?' have a similarity score of 0.82\n",
            "Questions 'How often do you engage with AI-based tools or technologies?' and 'Which AI-powered tools or applications do you use regularly?' have a similarity score of 0.80\n",
            "Questions 'Any final thoughts or suggestions you would like to share about the future of AI?' and 'How optimistic are you about AI’s role in shaping the future?' have a similarity score of 0.78\n",
            "Enter the location URL of the Excel file containing the responses (for logical connection analysis): /content/survey-29 (5).xlsx\n",
            "Logical Connection Score: 0.01\n",
            "Enter the location URL of the Excel file for BGT model analysis: /content/processed_data2.xlsx\n",
            "Predictions for the test data:\n",
            "Row 1: The survey was a genuine attempt with probability 94.92%\n",
            "BGT Model Score: 0.00\n",
            "Final Score: 0.00\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pickle\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Initialize the SentenceTransformer model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Load the BGT model from the saved pickle file\n",
        "with open('/content/bgt_model.pkl', 'rb') as f:\n",
        "    bgt_model = pickle.load(f)\n",
        "\n",
        "def check_logical_connection(question1, question2, answer1, answer2, question_threshold=0.75, answer_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Determines logical connection between questions and their answers based on similarity thresholds.\n",
        "    \"\"\"\n",
        "    # Encode questions and answers\n",
        "    question1_embedding = model.encode(question1)\n",
        "    question2_embedding = model.encode(question2)\n",
        "    answer1_embedding = model.encode(answer1)\n",
        "    answer2_embedding = model.encode(answer2)\n",
        "\n",
        "    # Calculate cosine similarity for questions\n",
        "    question_similarity = util.cos_sim(question1_embedding, question2_embedding).item()\n",
        "\n",
        "    if question_similarity >= question_threshold:\n",
        "        # If questions are similar, check the similarity of the answers\n",
        "        answer_similarity = util.cos_sim(answer1_embedding, answer2_embedding).item()\n",
        "\n",
        "        if answer_similarity >= answer_threshold:\n",
        "            return True, question_similarity, answer_similarity  # Both questions and answers are logically connected\n",
        "\n",
        "    return False, question_similarity, None\n",
        "\n",
        "def calculate_logical_connection_score(questions, options, df):\n",
        "    \"\"\"\n",
        "    Calculates the logical connection score based on the number of connected questions.\n",
        "    \"\"\"\n",
        "    connected_count = 0\n",
        "    total_comparisons = 0\n",
        "\n",
        "    for q1_id, q1_text in questions.items():\n",
        "        for q2_id, q2_text in questions.items():\n",
        "            if q1_id != q2_id:\n",
        "                total_comparisons += 1\n",
        "                for i, row in df.iterrows():\n",
        "                    answer1 = row[q1_text] if pd.notna(row[q1_text]) else \"\"\n",
        "                    answer2 = row[q2_text] if pd.notna(row[q2_text]) else \"\"\n",
        "                    is_connected, _, _ = check_logical_connection(q1_text, q2_text, answer1, answer2)\n",
        "                    if is_connected:\n",
        "                        connected_count += 1\n",
        "\n",
        "    logical_connection_score = (connected_count / total_comparisons) if total_comparisons > 0 else 0\n",
        "    return logical_connection_score\n",
        "\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    Preprocesses the data by encoding categorical variables and handling missing values.\n",
        "    \"\"\"\n",
        "    # Define features and target\n",
        "    X = data.drop('Category', axis=1)  # Drop the target column\n",
        "    y = data['Category']  # Target column\n",
        "\n",
        "    # Encode the target variable\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "    # Convert non-numeric columns to numeric using one-hot encoding\n",
        "    X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "    return X_encoded, y_encoded\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to process the survey script, identify related questions,\n",
        "    and analyze logical connections in the responses.\n",
        "    \"\"\"\n",
        "    # Prompt user to enter survey script in JSON format\n",
        "    survey_script = input(\"Enter the survey script in JSON format: \")\n",
        "    survey_data = json.loads(survey_script)\n",
        "\n",
        "    # Extract questions and options\n",
        "    questions = {q['id']: q['questionText'] for q in survey_data['questions']}\n",
        "    options = {q['id']: q['options'] for q in survey_data['questions']}\n",
        "\n",
        "    # Print related questions based on question similarity\n",
        "    print(\"Related Questions with Similarity Scores:\")\n",
        "    for q1_id, q1_text in questions.items():\n",
        "        for q2_id, q2_text in questions.items():\n",
        "            if q1_id != q2_id:\n",
        "                _, question_similarity, _ = check_logical_connection(q1_text, q2_text, \"\", \"\")\n",
        "                if question_similarity >= 0.75:  # Adjust threshold as needed\n",
        "                    print(f\"Questions '{q1_text}' and '{q2_text}' have a similarity score of {question_similarity:.2f}\")\n",
        "\n",
        "    # Load survey responses from an Excel file (for logical connection analysis)\n",
        "    logical_excel_url = input(\"Enter the location URL of the Excel file containing the responses (for logical connection analysis): \")\n",
        "    logical_df = pd.read_excel(logical_excel_url, sheet_name='Responses')\n",
        "\n",
        "    # Calculate logical connection score\n",
        "    logical_connection_score = calculate_logical_connection_score(questions, options, logical_df)\n",
        "    print(f\"Logical Connection Score: {logical_connection_score:.2f}\")\n",
        "\n",
        "    # Load BGT Excel file\n",
        "    bgt_excel_url = input(\"Enter the location URL of the Excel file for BGT model analysis: \")\n",
        "    bgt_df = pd.read_excel(bgt_excel_url, sheet_name='Sheet1')\n",
        "\n",
        "    # Preprocess the BGT data\n",
        "    bgt_features = bgt_df[['Selection_Pattern', 'Unique_Options', 'Most_Common_Option', 'Diversity_Score', 'Total_Time_Per_Response', 'Total_Sub_Length', 'Total_Sub_Time', 'Avg_Typing_Speed', 'Non-attempt']]\n",
        "    bgt_features_encoded = pd.get_dummies(bgt_features, drop_first=True)\n",
        "\n",
        "    # Ensure the BGT data has the same columns as the training data\n",
        "    missing_cols = set(X_train.columns) - set(bgt_features_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        bgt_features_encoded[col] = 0\n",
        "    bgt_features_encoded = bgt_features_encoded[X_train.columns]\n",
        "\n",
        "    # Predict using the trained BGT model\n",
        "    bgt_prediction = bgt_model.predict(bgt_features_encoded)\n",
        "    bgt_proba = bgt_model.predict_proba(bgt_features_encoded)\n",
        "\n",
        "    # Print the predictions with probabilities\n",
        "    print(\"Predictions for the test data:\")\n",
        "    for i in range(len(bgt_prediction)):\n",
        "        if bgt_prediction[i] == 0:\n",
        "            print(f\"Row {i+1}: The survey was a genuine attempt with probability {bgt_proba[i][0] * 100:.2f}%\")\n",
        "        else:\n",
        "            print(f\"Row {i+1}: The survey was a rush attempt with probability {bgt_proba[i][1] * 100:.2f}%\")\n",
        "\n",
        "    # Calculate BGT model score\n",
        "    bgt_score = np.mean(bgt_prediction)  # Assuming the prediction is a binary classification\n",
        "    print(f\"BGT Model Score: {bgt_score:.2f}\")\n",
        "\n",
        "    # Combine scores using weighted average (20% logical connection, 80% BGT model)\n",
        "    final_score = (0.3 * logical_connection_score) + (0.7 * bgt_score)\n",
        "    print(f\"Final Score: {final_score:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}